{
    "$schema": "http://json-schema.org/draft-07/schema#",
    "title": "Run Initialisation Parameters (Payload)",
    "description": "Hyperparameter fields required of a partipant in PySyft FL training",
    "type": "object",
    "properties": {

        "run_id": {
            "description": "Unique Identifier for an experiment run",
            "type": "string"
        },

        "input_size": {
            "description": "No. of nodes in the input layer (i.e. features) AFTER MFA",
            "type": "integer"
        },
        
        "output_size": {
            "description": "No. of nodes in the output layer (i.e. targets) AFTER MFA",
            "type": "integer"
        },
        
        "batch_size": {
            "description": "Size of each minibatch",
            "type": "integer"
        },
        
        "rounds": {
            "description": "No. of rounds to cycle training for global model",
            "type": "integer"
        },
        
        "epochs": {
            "description": "No. of local epochs for training each local model",
            "type": "integer"
        },
        
        "lr": {
            "description": "Learning rate of gradient training",
            "type": "number"
        },
        
        "lr_decay": {
            "description": "Decay rate applied to learning rate",
            "type": "number"
        },

        "weight_decay": {
            "description": "L2 regularisation term, synonymous to 'l2_lambda'. Use 'l2_lambda' instead!",
            "type": "number"
        },

        "seed": {
            "description": "Seeding value used for fixing RNG",
            "type": "integer"
        },
        
        "is_condensed": {
            "description": "Toggles between Binary & Multiclass classification",
            "type": "boolean"
        },

        "precision_fractional": {
            "description": "States no. of decimal places to fix gradients to",
            "type": "integer"
        },

        "use_CLR": {
            "description": "Toggles whether specialised Cyclic learning rate decay is used",
            "type": "boolean"
        },

        "mu": {
            "description": "FedProx regularisation term",
            "type": "number"
        },

        "reduction": {
            "description": "Reduction to apply to the output",
            "type": "string",
            "enum": ["none", "mean", "sum"]
        },
                    
        "l1_lambda": {
            "description": "L1 regularisation term",
            "type": "number"
        },

        "l2_lambda": {
            "description": "L2 regularisation term",
            "type": "number"
        },

        "dampening": {
            "description": "Dampening for momentum",
            "type": "number"
        },
        
        "base_lr": {
            "description": "L2 regularisation term, synonymous to 'l2_lambda'. Use 'l2_lambda' instead!",
            "type": "number"
        },

        "max_lr": {
            "description": "L2 regularisation term, synonymous to 'l2_lambda'. Use 'l2_lambda' instead!",
            "type": "number"
        },

        "step_size_up": {
            "description": "No. of training iterations in the increasing half of a cycle",
            "type": "integer"
        },

        "step_size_down": {
            "description": "No. of training iterations in the decreasing half of a cycle",
            "type": "integer"
        },

        "mode": {
            "description": "Toggles whether 'scale_fn' is evaluated on cycle number or cycle iterations",
            "type": "string",
            "enum": ["triangular", "triangular2", "exp_range"]
        },
        
        "gamma": {
            "description": "Constant in ‘exp_range’ scaling function: gamma**(cycle iterations)",
            "type": "number"
        },
        
        "scale_mode": {
            "description": "Toggles whether 'scale_fn' is evaluated on cycle number or cycle iterations",
            "type": "string",
            "enum": ["cycle", "iterations"]
        },

        "cycle_momentum": {
            "description": "momentum is cycled inversely to learning rate between 'base_momentum' and 'max_momentum'",
            "type": "boolean"
        },

        "base_momentum": {
            "description": "Lower momentum boundaries in the cycle for each parameter group",
            "type": "number"
        },

        "max_momentum": {
            "description": "Upper momentum boundaries in the cycle for each parameter group",
            "type": "number"
        },

        "last_epoch": {
            "description": "Index of the last epoch",
            "type": "integer"
        },

        "patience": {
            "description": "No. of stagnated epochs allowed before earlystopping is employed",
            "type": "integer"
        },

        "delta": {
            "description": "Min loss change required to be considered as an improvement",
            "type": "number"
        },

        "cumulative_delta": {
            "description": "Cumulative delta allowed before earlystopping is employed",
            "type": "boolean"
        }
    }
} 
