1) **Clone this repository**
    ```bash
    git clone https://github.com/aimakerspace/synergos_ttp.git
    ```

2) **Navigate into the repository**
    ```bash
    cd ./synergos_ttp
    ```

2) **Checkout to stable tag**
    ```bash
    git checkout tags/v0.1.0
    ```

3) **Update Submodule**
    ```bash
    git submodule update --init --recursive
    git submodule update --recursive --remote
    ```

4) **Build Synergos Basic image using the following command(s):** 
    ```bash
    docker build --target basic_ttp -t synergos_ttp:v0.1.0 --label "WebsocketClientWorker" .
    ```

5) **Build Synergos Cluster image using the following command(s):** 
    ```bash
    docker build --target syncluster_ttp -t synergos_ttp_cluster:v0.1.0 --label "WebsocketClientWorker" .
    ```

6) **Make sure that the worker containers have already started running (i.e. primed for WS handshake. Instructions for worker startup can be found [here](https://github.com/aimakerspace/synergos_worker).**


7) **Set up the appropriate mountpoint directories.**

    A. Data

    > <font color='turquoise'>**/data <br>&ensp;&ensp;&ensp;&ensp;< no structural requirements >**</font>

    There are no structural requirements for the `data` directory. This internal directory is meant to be overridden by your own data directory. Database files are generated by the system here.

    B. Outputs

    > <font color='turquoise'>**/outputs <br>&ensp;&ensp;&ensp;&ensp;< no structural requirements >**</font>

    There are no structural requirements for the `outputs` directory. This internal directory is meant to be overridden by your own data directory. Cached file outputs from federated processes are found here.

    C. MLFlow Cache Directory

    > <font color='turquoise'>**/mlflow_test <br>&ensp;&ensp;&ensp;&ensp;< no structural requirements >**</font>

    There are no structural requirements for the `mlflow_test` directory. This internal directory is meant to be overridden by your own data directory. Cached files generated from MLFlow logging will be exported here, where they can be fed as backend-URIs to an MLFlow server for analyses and visualisation.

8) **Start up the TTP node. Start-up commands can be reduced depending on whether or not you are running the REST-RPC grid in standalone mode, or over a distributed network. In general, it is as follows:**

    ** When running TTP Basic configuration
    ```bash
    docker run \
        -p <host>:<f_port>:5000 \
        -p <host>:<ws_port>:8020 \
        -v /path/to/data_export_directory/ttp_data:/ttp/data \
        -v /path/to/outputs_export_directory:/ttp/outputs \
        -v /path/to/outputs_export_directory/mlflow_test:/ttp/mlflow \
        -v /path/to/mlflow_export_directory:/ttp/mlflow \
        --name ttp synergos_ttp:v0.1.0
    ```

    ** When running TTP Cluster configuration
    ```bash
    docker run \
        -p <host>:<f_port>:5000 \
        -v /path/to/data_export_directory/ttp_data:/ttp/data \
        -v /path/to/outputs_export_directory:/ttp/outputs \
        -v /path/to/outputs_export_directory/mlflow_test:/ttp/mlflow \
        -v /path/to/mlflow_export_directory:/ttp/mlflow \
        --name ttp synergos_ttp_cluster:v0.1.0 \
        --id ttp --logging_variant basic \ 
        --queue rabbitmq <mq-vm-ip> 5672 \
        --censored
    ```

    <!-- Let's try to break down what is going on here. -->

    A. Port Routes
    ```bash
        -p <host>:<f_port>:5000 \
        -p <host>:<ws_port>:8020
    ```

    This section maps the incoming connections into the container. 
    
    <!-- In the REST-RPC worker, the 2 main services hosted are:
        
    1. Static REST service

        * Driven by Flask
        * Receives triggers from REST-RPC TTP

    2. Dynamically initialised websocket connection

        * Primarily used by PySyft workers for finetuned federated orchestration.
        * Only active when PySyft's `WebsocketClientWorkers` (WSCWs) have been initialised to complete the websocket connecton with the worker nodes' `WebsocketServerWorkers` (WSSWs) (internally handled)
        * Deactivates when WSCWs are destroyed (internally handled) -->

    Glossary:
     
    * host - IP of host machine
    * f_port - Selected port to route incoming HTTP connections for the REST service
    * ws_port - Selected port to route incoming Websocket connections for the PySyft Websocket workers
    * mq-vm-ip - IP of selected VM running Synergos MQ component required in Synergos Cluster configuration

    B. Volume Mounts
    ```bash
        -v /path/to/data_export_directory:/ttp/data \
        -v /path/to/outputs_export_directory:/ttp/outputs \
        -v /path/to/mlflow_export_directory:/ttp/mlflow
    ```

    As mentioned in step 7., override the internal directories of the containers with the mountable directories you have created.

    C. Launch Examples

    You can view the guides for running:
    - [Synergos Basic Standalone Grid i.e. local](https://docs.synergos.ai/BasicRunLocal.html)
    - [Synergos Basic Distributed Grid i.e. across multiple devices](https://docs.synergos.ai/BasicRunDistributed.html)
    - [Synergos Cluster Distributed Grid i.e. across multiple devices](https://docs.synergos.ai/ClusterRunDistributed.html)
    - [Example Datasets and Jupyter Notebooks](https://github.com/aimakerspace/Synergos/tree/master/examples)

    <!-- I. Standalone Grid (i.e. local)

    ><font color='turquoise'>**docker run <br> -p <f_port>:5000<br>-v /path/to/data_export_directory:/ttp/data <br> -v /path/to/outputs_export_directory:/ttp/outputs <br> -v /path/to/mlflow_export_directory:/ttp/mlflow <br>--name ttp ttp:pysyft_demo**</font>
     
    In a standalone grid, docker's bridge network automatically assigns an IP to each container. This means that each container has a unique IP and thus is not required to perform port routing. However, you will still have to reroute a port so that the container can receive instructions from the driver node (i.e. machine that the TTP user is on)

    > To find your container IDs, use either <br>`docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' container_name_or_id` for modern version of docker, or <br>`docker inspect --format '{{ .NetworkSettings.IPAddress }}' container_name_or_id` for the previous versions.

    II. Distributed Servers (i.e. across multiple devices)

    ><font color='turquoise'>**docker run <br><font color='red'>-p <host\>:<f_port\>:5000 <br> -p <host\>:<ws_port\>:8020</font><br><font color='orange'>-v /path/to/data_export_directory:/ttp/data <br> -v /path/to/outputs_export_directory:/ttp/outputs <br> -v /path/to/mlflow_export_directory:/ttp/mlflow</font><br> --name ttp ttp:pysyft_demo**</font>
    
    For a guided tutorial, 
    1. Download worker inputs [here](https://drive.google.com/drive/folders/1hSoOq1z-Lo3w-qUrFbsoPITzIyYWivvD?usp=sharing)
    2. Download test datasets [here](https://drive.google.com/drive/folders/19C9m6XEPHeEMIwmPRajX5-UBNujGOdtM?usp=sharing)
    3. Refer to this [guide](https://gitlab.int.aisingapore.org/aims/federatedlearning/fedlearn-prototype/-/wikis/PySyft/How-to-run-jobs-in-PySyft). -->

